<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Voice Assistant</title>
  <style>
    body { font-family: sans-serif; text-align: center; margin-top: 60px; }
    button { padding: 10px 20px; font-size: 18px; margin: 10px; }
    audio { margin-top: 20px; }
  </style>
</head>
<body>
  <h1>🎤 AI Voice Assistant</h1>
  <button id="recordBtn">Start Recording</button>
  <button id="stopBtn" disabled>Stop & Send</button>
  <p id="status">Waiting...</p>
  <audio id="responseAudio" controls></audio>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let baseUrl = "";
  
    const recordBtn = document.getElementById('recordBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusText = document.getElementById('status');
    const responseAudio = document.getElementById('responseAudio');
  
    // Detect if iOS device
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
  
    // Fetch base URL from backend config
    fetch("/calls/config")
      .then(res => res.json())
      .then(config => {
        baseUrl = config.ngrok_base_url.replace(/\/$/, ""); // remove trailing slash
        console.log("✅ Using base URL:", baseUrl);
      })
      .catch(err => {
        console.error("❌ Failed to load config:", err);
        statusText.textContent = "Error loading backend config.";
      });
  
    recordBtn.onclick = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const mimeType = isIOS ? 'audio/mp4' : 'audio/webm';
        mediaRecorder = new MediaRecorder(stream, { mimeType });
        audioChunks = [];
  
        mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
  
        mediaRecorder.onstart = () => {
          statusText.textContent = '🎙️ Recording...';
          recordBtn.disabled = true;
          stopBtn.disabled = false;
  
          // Optional: auto-stop after 10s to prevent long replies
          setTimeout(() => {
            if (mediaRecorder.state === 'recording') {
              mediaRecorder.stop();
            }
          }, 10000); // 10 seconds
        };
  
        mediaRecorder.onstop = async () => {
          statusText.textContent = '⏳ Processing...';
          recordBtn.disabled = false;
          stopBtn.disabled = true;
  
          const fileExtension = isIOS ? 'mp4' : 'webm';
          const fileType = isIOS ? 'audio/mp4' : 'audio/webm';
          const audioBlob = new Blob(audioChunks, { type: fileType });
          const formData = new FormData();
          formData.append('file', audioBlob, `input.${fileExtension}`);
  
          try {
            const response = await fetch(`${baseUrl}/calls/simulate/ai-call`, {
              method: 'POST',
              body: formData
            });
  
            const blob = await response.blob();
            responseAudio.src = URL.createObjectURL(blob);
            statusText.textContent = '✅ Response ready';
          } catch (error) {
            console.error("❌ Error sending audio:", error);
            statusText.textContent = '⚠️ Failed to reach backend.';
          }
        };
  
        mediaRecorder.start();
      } catch (err) {
        console.error("🎤 Mic access error:", err);
        alert("Microphone not supported on this device or browser.");
      }
    };
  
    stopBtn.onclick = () => {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
      }
    };
  </script>
  
</body>
</html>
